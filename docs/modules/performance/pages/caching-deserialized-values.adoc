= Caching Deserialized Values

There may be cases where you do not want to deserialize some values in your Hazelcast map again which were already deserialized previously.
This way your query operations get faster.
This is possible by using the `cache-deserialized-values` element in your declarative Hazelcast configuration, as shown below.

[tabs] 
==== 
XML:: 
+ 
-- 
[source,xml]
----
<hazelcast>
    ...
    <map name="myMap">
        <in-memory-format>BINARY</in-memory-format>
        <cache-deserialized-values>INDEX-ONLY</cache-deserialized-values>
        <backup-count>1</backup-count>
    </map>
    ...
</hazelcast>
----
--

YAML::
+
[source,yaml]
----
hazelcast:
  map:
    myMap:
      in-memory-format: BINARY
      cache-deserialized-values: INDEX-ONLY
      backup-count: 1
----
====

The `cache-deserialized-values` element controls the caching of deserialized values.
Note that caching makes the query evaluation faster, but it consumes more memory. This element has the following values:

* NEVER: Deserialized values are never cached.
* INDEX-ONLY: Deserialized values are cached only when they are inserted into an index.
* ALWAYS: Deserialized values are always cached.

If you are using portable serialization or your map's in-memory format is `OBJECT` or `NATIVE`,
then `cache-deserialized-values` element does not have any effect.

== Performance Anti Patterns

This section covers various recommendations to improve the performance of your Hazelcast IMDG clusters.

=== Using Single Member per Machine

A Hazelcast member assumes it is alone on a machine, so we recommend not running multiple
Hazelcast members on a machine. Having multiple
members on a single machine most likely gives a worse performance compared to
running a single member, since there will be more
context switching, less batching, etc. So unless it is proven that running multiple members per machine does give a better
performance/behavior in your particular setup, it is best to run a single member per machine.

=== Using Operation Threads Efficiently

By default, Hazelcast uses the machine's core count to determine the number of operation threads. Creating more
operation threads than this core count is highly unlikely leads to an improved performance since there will be more context
switching, more thread notification, etc.

Especially if you have a system that does simple operations like put and get,
it is better to use a lower thread count than the number of cores.
The reason behind the increased performance
by reducing the core count is that the operations executed on the operation threads normally execute very fast and there can
be a very significant amount of overhead caused by thread parking and unparking. If there are less threads, a thread needs
to do more work, will block less and therefore needs to be notified less.

=== Avoiding Random Changes

Tweaking can be very rewarding because significant performance improvements are possible. By default, Hazelcast tries 
to behave at its best for all situations, but this doesn't always lead to the best performance. So if you know what
you are doing and what to look for, it can be very rewarding to tweak. However it is also important that tweaking should
be done with proper testing to see if there is actually an improvement. Tweaking without proper benchmarking
is likely going to lead to confusion and could cause all kinds of problems. In case of doubt, we recommend not to tweak.

=== Creating the Right Benchmark Environment

When benchmarking, it is important that the benchmark reflects your production environment. Sometimes with calculated
guess, a representative smaller environment can be set up; but if you want to use the benchmark statistics to inference
how your production system is going to behave, you need to make sure that you get as close as your production setup as
possible. Otherwise, you are at risk of spotting the issues too late or focusing on the things which are not relevant.